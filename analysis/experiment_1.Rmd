---
title: "Differential influence of habit components on problematic behaviors - Experiment 1"
author: "Lavinia Wuensch, Yoann Stussi, Th√©o Vernede, Eva R. Pool"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

# Experiment 1

```{r setup, echo=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

# Load libraries
library(here)
library(car)
library(afex)
library(doBy)
library(ggplot2)
library(viridis)
library(ggExtra)
library(viridis)
library(jtools)
library(plyr)
library(dplyr)
library(tidyr)
library(psych)
library(devtools)
library(GPArotation)
library(nFactors)
library(RGenData)
library(lavaan)
library(semPlot)
library(data.table)
library(reshape2)
library(Hmisc)
library(tidyverse)
library(ggpubr)

# Network analysis
library(corrplot)
library(RColorBrewer)
library(bootnet)
library(networktools)
library(NetworkComparisonTest)
library(qgraph)

# For html file 
library(JWileymisc)
library(kableExtra)
library(knitr)
```

```{r load_data, include = FALSE}
# Set up paths
data_path <- here::here("databases")
figures_path <- here::here("figures")
utilities_path <- here::here("analysis", "functions")
results_path <- here::here("results")

# Custom functions
source(file.path(utilities_path,'cpplus.r'))
source(file.path(utilities_path,'setup.r'))
```

```{r setup_specific, include = FALSE}
# Remove participants that have missing data on at least one of the
# questionnaires of interest for Experiment 1 only

# Questionnaires of interest
var.totals <- c(
  "CESD_total",
  "COHS_total",
  "EAT26_total",
  "IAT_total",
  "OCIR_total",
  "PMPUQSV_total",
  "PSS_total",
  "UPPS_total",
  "STAIT_total",
  "sub"
)

db.totals <- Q1[var.totals]

# Remove missing
no.missingdata = na.omit(db.totals )

# Select only participants that do not have missing data on questionnaires of interest
Q1 = subset (Q1, (sub) %in% no.missingdata$sub)

# Save database
saveRDS(Q1, str_c(results_path, "/experiment_1_items.rds"))
```

## Population demographics

Total included participants:

```{r population, echo = TRUE}
# Count participants
count.participants <- plyr::count(Q1, c("sub"))
sum(count.participants$freq)
```

Gender and age:

```{r demo, echo=TRUE}
var.demo <- c('Age','Genre')
db.demo <- Q1[var.demo]
db.demo$Genre <- factor (db.demo$Genre)

table_demo_exp1 <- JWileymisc::egltable(c("Age", "Genre"), 
                      data = db.demo[c("Age","Genre")], strict = FALSE) %>%
  kbl(caption ="Demographics of sample used for Experiment 1", digits = 2)    %>%
  kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_demo_exp1


# Get only the language
dem.lang <- c("Langue[1]","Langue[2]","Langue[3]")
db.lang <- Q1[dem.lang]

# Rename columns so that we know what they mean
colnames(db.lang)[colnames(db.lang) == "Langue[1]"] <- "French_dominant"
colnames(db.lang)[colnames(db.lang) == "Langue[2]"] <- "French_good"
colnames(db.lang)[colnames(db.lang) == "Langue[3]"] <- "French_medium"

# Define factors
db.lang$French_dominant = factor(db.lang$French_dominant)
db.lang$French_good = factor(db.lang$French_good)
db.lang$French_medium = factor(db.lang$French_medium)

# Describe
summary(db.lang)
describe(db.lang)
```

## Descriptives analysis

Get means, n and standard deviations of the questionnaires.

```{r descriptives_stats_gender, echo=TRUE}
var.totals_gender <- c("CESD_total",
                   "COHS_total",
                   "EAT26_total",
                   "IAT_total",
                   "OCIR_total",
                   "PMPUQSV_total",
                   "PSS_total", 
                   "UPPS_total",
                   "STAIT_total",
                "Genre")

db.totals_gender <- Q1[var.totals_gender]
q1.descr_gender <- psych::describeBy(db.totals_gender, group = db.totals_gender$Genre)

# For the UPPS we used two different versions for B1 and B2 
B23 = subset(Q1, dataset != 'B1')
B1 = subset(Q1, dataset == 'B1')

var.B1.subscale_gender <- c("UPPS_total_raw", "Genre")
db.subscale.B1_gender <- B1[var.B1.subscale_gender]
q1.descr1_gender = psych::describeBy(db.subscale.B1_gender, db.subscale.B1_gender$Genre)

var.B23.subscale_gender <- c("UPPS_total_raw", "Genre")

db.subscale.B23_gender <- B23[var.B23.subscale_gender]
q1.descr2_gender = psych::describeBy(db.subscale.B23_gender, group = db.subscale.B23_gender$Genre)

# Combine all descriptive values in single datasets
a_gender_f = rbind(q1.descr_gender$F,q1.descr1_gender$F)
aa_gender_f = rbind (a_gender_f, q1.descr2_gender$F)

table_exp1_desc_gender_f <- knitr::kable(aa_gender_f, "html", caption = "Descriptive values for questionnaire of Experiment 1") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_desc_gender_f

# Combine all descriptive values in single datasets
a_gender_m = rbind(q1.descr_gender$M,q1.descr1_gender$M)
aa_gender_m = rbind (a_gender_m, q1.descr2_gender$M)

table_exp1_desc_gender_m <- knitr::kable(aa_gender_m, "html", caption = "Descriptive values for questionnaire of Experiment 1") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_desc_gender_m

# Combine all descriptive values in single datasets
a_gender_nonbinary = rbind(q1.descr_gender$`N/A`,q1.descr1_gender$`N/A`)
aa_gender_nonbinary = rbind (a_gender_nonbinary, q1.descr2_gender$`N/A`)

table_exp1_desc_gender_nonbinary <- knitr::kable(aa_gender_nonbinary, "html", caption = "Descriptive values for questionnaire of Experiment 1") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_desc_gender_nonbinary
```

```{r descriptives_stats, echo=TRUE}
var.totals <- c("CESD_total",
                   "COHS_total",
                   "EAT26_total",
                   "IAT_total",
                   "OCIR_total",
                   "PMPUQSV_total",
                   "PSS_total", 
                   "UPPS_total",
                   "STAIT_total")


db.totals <- Q1[var.totals]
q1.descr = psych::describe(db.totals)

# For the UPPS we used two different versions for B1 and B2 
B23 = subset(Q1, dataset != 'B1')
B1 = subset(Q1, dataset == 'B1')

var.B1.subscale <- c("UPPS_total_raw")
db.subscale.B1 <- B1[var.B1.subscale]
q1.descr1 = psych::describe(db.subscale.B1)

var.B23.subscale <- c("UPPS_total_raw")

db.subscale.B23 <- B23[var.B23.subscale]
q1.descr2 = psych::describe(db.subscale.B23)

# Combine all descriptive values in single datasets
a = rbind(q1.descr,q1.descr1)
aa = rbind (a, q1.descr2)

table_exp1_desc <- knitr::kable(aa, "html", caption = "Descriptive values for questionnaire of Experiment 1") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_desc
```

## Compute alpha

```{r alphas, echo=TRUE}
my.scales <- scoreItems(Q1.alphas,Q1)
my.scales$alpha

# UPPS B1
col_UPPS_short <- paste("UPPS[", 1:20, "]", sep = "")
SHORT = list(UPPS = col_UPPS_short)
my.scales.uppss <- scoreItems(SHORT,B1)
my.scales.uppss$alpha

# UPPS B23
col_UPPS_long <- paste("UPPS[", 1:40, "]", sep = "")
LONG= list(UPPS = col_UPPS_long)
my.scales.uppsl <- scoreItems(SHORT,B23)
my.scales.uppsl$alpha
```

```{r plot_distribution, echo=TRUE, warning=FALSE, message=FALSE}
var.totals <- c("CESD_total",
                   "COHS_total",
                   "EAT26_total",
                   "IAT_total",
                   "OCIR_total",
                   "PMPUQSV_total",
                   "PSS_total", 
                   "UPPS_total",
                   "STAIT_total"
             )

db.totals <- Q1[var.totals]

# Pivot to long format for plots
db_long <- gather(db.totals, questionnaire , score, CESD_total:STAIT_total, factor_key=TRUE)

# Save database for revisions
saveRDS(db_long, str_c(results_path, "/experiment_1_questionnaires.rds"))

# Labels
labels <- c(CESD_total = "CES-D", 
            COHS_total = "COHS",
            EAT26_total = "EAT", 
            IAT_total = "IAT", 
            PSS_total = "PSS",
            OCIR_total = "OCI", 
            UPPS_total = "UPPS",
            STAIT_total = "STAI-T",
            PMPUQSV_total = "PMPUQ")

# Plot distributions
pp = ggplot(data = db_long, aes (x = score, fill = questionnaire)) +
  facet_wrap(~questionnaire, scales = "free", labeller = labeller(questionnaire = labels) ) +
  geom_histogram(aes(y=..density..),alpha=0.6) +
  geom_density(aes(color = questionnaire), alpha = 0.3) +
    scale_fill_viridis_d(name = "Questionnaires", 
                       begin = .1, end = .9,
                       option = "inferno",
                       aesthetics = c("color", "fill"),
                       labels = labels)+
  theme_bw()+
  labs(
    title = '',
    x = 'Questionnaires',
    y = "Frequency"
  )

# Make plot nicer
ppp <-   pp + theme_bw(base_size = 10, base_family = "Helvetica")+
  theme(strip.text.x = element_text(size = 10, face = "bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.background = element_rect(color="white", fill="white", linetype="solid"),
        axis.ticks.x = element_blank(),
        axis.text.x  = element_blank(),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        legend.position = "none")

ppp

# Print the plot to pdf
pdf(file.path(figures_path, 'experiment_1_questionnaire_distributions.pdf'))
print(ppp)
dev.off()
```

```{r plot_cohs_subscales, echo=TRUE, warning=FALSE, message=FALSE}
# Get subscale item lists
routine_items <- c(
  "[15]", "[27]", "[13]", "[6]", "[24]", "[2]", "[12]", "[17]", "[7]", "[10]", 
  "[20]", "[1]", "[22]", "[18]", "[4]", "[14]"
  )
automaticity_items <- c(
  "[11]", "[25]", "[3]", "[23]", "[19]", "[26]", "[8]", "[9]", "[16]", "[5]",
  "[21]"
)

# Get COHS subscales
df_cohs <- Q1 %>%
  select(
    sub,
    (starts_with("COHS") & ends_with("]"))
    ) %>%
  rowwise(sub) %>%
  # Total
  dplyr::mutate(cohs_total = sum(across(starts_with("COHS")), na.rm = TRUE)) %>%
  # Subscales
  dplyr::mutate(cohs_routine = sum(across(ends_with(routine_items)), na.rm = TRUE)) %>%
  dplyr::mutate(cohs_automaticity = sum(
    across(ends_with(automaticity_items)), na.rm = TRUE)
    ) %>%
  ungroup()

# Pivot to long format for plots
df_cohs_plot <- df_cohs %>%
  select(sub, starts_with("cohs_")) %>%
    pivot_longer(
    cols = !sub,
    names_to = c("scale"),
    names_pattern = "cohs_(.*)"
    )

# Labels
labels <- c(routine = "COHS Routine",
            automaticity = "COHS Automaticity",
            total = "COHS Total")

# Plot distribution
pp = ggplot(data = df_cohs_plot, aes (x = value, fill = scale)) +
  facet_wrap(~scale, scales = "free", labeller = labeller(scale = labels)) +
  geom_histogram(aes(y=..density..),alpha=0.6) +
  geom_density(aes(color = scale), alpha = 0.3) +
    scale_fill_viridis_d(name = "Questionnaires", 
                       begin = .1, end = .9,
                       option = "inferno",
                       aesthetics = c("color", "fill"),
                       labels = labels)+
  theme_bw()+
  labs(
    title = '',
    x = "Experiment 1",
    y = "Frequency"
  )

# Make plot nicer
ppp <-   pp + theme_bw(base_size = 10, base_family = "Helvetica")+
  theme(strip.text.x = element_text(size = 10, face = "bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.background = element_rect(color="white", fill="white", linetype="solid"),
        # axis.ticks.x = element_blank(),
        # axis.text.x  = element_blank(),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        legend.position = "none")

ppp

# Print plot to pdf
ggsave(paste0(figures_path, "/experiment_1_cohs_subscales.pdf"), ppp, width = 25, height = 12, units = "cm")

saveRDS(df_cohs_plot, str_c(results_path, "/experiment_1_cohs.rds"))
```

## Extract Factors from subscales

```{r efa_describe, echo=TRUE} 
# Select subscales
var.subscales <- c("CESD_depressed",
                   "CESD_positive",
                   "CESD_somatic",
                   "CESD_relationship",
                   "EAT26_oral_control",
                   "EAT26_dieting",
                   "EAT26_bulimia",
                   "IAT_salience",
                   "IAT_excessive_use",
                   "IAT_neglect_work",
                   "IAT_anticipation",
                   "IAT_lack_control",
                   "IAT_neglect_social_life",
                   "OCIR_Washing",
                   "OCIR_checking",
                   "OCIR_ordering",
                   "OCIR_obsessing",
                   "OCIR_hoarding",
                   "OCIR_neutralising",
                   "PMPUQSV_dangerous",
                   "PMPUQSV_prohibited",
                   "PMPUQSV_dependant",
                   "PSS_total",                       
                   "STAIT_total"
)

db.efa.exp1 <- Q1[var.subscales]
db.efa.descr1 = psych::describe(db.efa.exp1)

table_exp1_efa_descr <- knitr::kable(db.efa.descr1 , "html", caption = "Descriptive values for subscales used in Experiment 1") %>%
  kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_efa_descr 
```

Verify postulates with KMO and Barlett test:

```{r efa_postulates, echo=TRUE} 
# Verify postulates
KMO(db.efa.exp1)

cor_matrix <- cor(db.efa.exp1, use = "complete.obs")

cortest.bartlett(cor_matrix, n = nrow(db.efa.exp1))
```

First, use parallel analysis method:

```{r efa_fa.parallel, echo=TRUE} 
nFact  <- fa.parallel(db.efa.exp1, fm = "ml")
```

Second, use VSS method:

```{r efa_vss, echo=TRUE} 
nFact  <- vss(db.efa.exp1) 
```

Third, nScree method:

```{r efa_nscreen, echo=TRUE} 
nFact  <- nScree(x = na.omit(db.efa.exp1), model = "factors") 

plotnScree(nFact) 
```

Try method "comparisons data":

```{r efa_compdata, echo=TRUE} 
nFact <- EFACompData(na.omit(db.efa.exp1), 8, n.pop = 10000, n.samples = 500, alpha = .30, graph = T,
                     corr.type = "pearson") #

```

# Apply EFA with 4 factors and an oblimin rotation

```{r efa_fa, echo=TRUE} 
quest.1.efa1 <- fa(r = db.efa.exp1, nfactors =4, rotate = "oblimin", fm = "ml")

print(quest.1.efa1$loadings,cutoff = 0.2)
```

## Compute factor scores 

We compute factor scores but importantly we assess factor indeterminacy to control if the factors can be used as predictors.

```{r efa_loading, echo=TRUE} 
s.exp1 = factor.scores (db.efa.exp1, quest.1.efa1) #
s.exp1$R2
```

## Plot correlation matrix between factors

```{r plot_correlation_matrix, echo=FALSE, warning=TRUE} 
fact_col_new  <- c( "CESD: depr.",
                   "CESD: pos.",
                   "CESD: somatic",
                   "CESD: relation.",
                   "EAT: oral contr.",
                   "EAT: dieting",
                   "EAT: bulimia",
                   "IAT: salience",
                   "IAT: exces. use",
                   "IAT: negl. work",
                   "IAT: anticip.",
                   "IAT: lack contr.",
                   "IAT: negl. social",
                   "OCI: wash.",
                   "OCI: check.",
                   "OCI: order.",
                   "OCI: obsess.",
                   "OCI: hoard.",
                   "OCI: neutr.",
                   "PMPUQ: danger.",
                   "PMPUQ: prohib.", 
                   "PMPUQ: depend.", 
                   "PSS",
                   "STAI-T")



col_old = var.subscales

colnames(db.efa.exp1)[colnames(db.efa.exp1) == var.subscales] <- fact_col_new
corrmatrix <- cor(db.efa.exp1, use="complete.obs")
col1 <- colorRampPalette(brewer.pal(9,"BrBG"))

corrplot(
  corrmatrix,
  method = "square",
  tl.col = "black", tl.cex = 0.75,
  sig.level = 0.05,
  insig = "pch", pch.cex = 1,
  col = col1(100),
  cl.pos = "b",
  cl.ratio = 0.1,
  tl.pos = "l"
  )
# dev.print(pdf, file.path(figures_path, "experiment_1_correlational_symptoms.pdf"))
# dev.off()
```

## Extract transdiagnostic factors based on the EFA

```{r plot_factor_loadings, echo=TRUE, message=FALSE, warning=FALSE}
# Get loadings into dataset
load = quest.1.efa1$loadings
load = load[]
load = data.frame(load)
setDT(load,keep.rownames=TRUE)[]
colnames(load)[1] <- "Subscale"

loadings.m <- melt(load, id="Subscale",
                   measure=c("ML3", "ML1","ML2", "ML4"),
                   variable.name="Factor", value.name="Loading")

# Name factors
labels <- c(ML3 = "Pr. media", ML1 = "Stress",
            ML2 = "Pr. eating", ML4 = "Compulsivity")

loadings.m$subscales = fact_col_new

loadings.m$subscales <- factor(loadings.m$subscales, levels = loadings.m$subscales[seq (1:24)])

pp <- ggplot(loadings.m, aes(subscales, abs(Loading), fill=Loading)) +
  facet_wrap(~ Factor, nrow=1, labeller = labeller(Factor = labels) ) +
  geom_bar(stat="identity") + #make the bars
  coord_flip() + #flip the axes so the test names can be horizontal
  scale_fill_gradient2(name = "Loading",
                       high = "#006666", mid = "white", low = "goldenrod4",
                       midpoint=0, guide=F) +
  scale_x_discrete(limits = rev(levels(loadings.m$subscales)))+
  ylab("Loading Strength") +
  theme_bw(base_size=10)

# Make plot nicer
ppp <-   pp + theme_bw(base_size = 10, base_family = "Helvetica")+
  theme(strip.text.x = element_text(size = 8, face = "bold"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        strip.background = element_rect(color="white", fill="white", linetype="solid"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        legend.position = "none")

ppp

dev.print(pdf, file.path(figures_path,'experiment_1_factors.pdf'))
dev.off()
```

## Factor correlations

```{r factor_correlation, echo=TRUE, message=FALSE, warning=FALSE}
var.net = c("COHS_automaticity", "COHS_routine","UPPS_total" )
db.network.tmp1 <- Q1[var.net]

# Merge with the full database
axes.exp1 <- s.exp1$scores

# Combine
db.network.exp1 <- cbind(db.network.tmp1, axes.exp1)

# Rename with interpreted factors
old_names = c ("COHS_automaticity", "COHS_routine", "UPPS_total",
               "ML1","ML3","ML2","ML4")

new_names <- c("Automaticity","Routine","Impuls.",
               "Stress","Media","Eat","Comp.")

colors <- c(pal[8], pal[8],pal[8],
            pal[9], pal[9], pal[9],
            pal[9])


colnames(db.network.exp1)[colnames(db.network.exp1) == old_names] <- new_names

# Descriptive correlation
factor_corr_plot <- cpplus(db.network.exp1, reorder=FALSE, alpha=0.05)

dev.print(pdf, file.path(figures_path, 'experiment_1_factors_correlation.pdf'))
dev.off()

# Save factors for revision
saveRDS(db.network.exp1, str_c(results_path, "/experiment_1_factors.rds"))
```

## Dynamic network analysis
 
Centrality table:

```{r network_centrality, echo=TRUE}
mynetwork.exp1 <- estimateNetwork(db.network.exp1, default ="EBICglasso") # EBIC hyperparameter is set to 0.5

CentralityTable <- centralityTable(mynetwork.exp1)

EITable <- subset(CentralityTable, measure == "ExpectedInfluence")

table_exp1_ei <- knitr::kable(EITable , "html", caption = "Centrality Table Experiment 2") %>%
 kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_ei
```

```{r network_analysis, echo=TRUE, message=FALSE, warning=FALSE}
nledges <- getWmat(mynetwork.exp1)

plot_network.exp1 <- qgraph(nledges,
       layout = "spring",
       labels = new_names,
       label.scale = F,
       label.cex = 1,
       edge.labels = F,
       color = colors,
       border.color = colors,
       border.width = 4,
       node.width = 0.9,
       posCol = c("#006666","#006666"),
       negCol = c("goldenrod4","goldenrod4"),
       vTrans = 150,
       label.font = 2
       )

dev.print(pdf, file.path(figures_path, 'experiment_1_network.pdf'))
print(plot_network.exp1)
dev.off()
```

## Estimate network edge weights accuracy and centrality measures stability

First for edges:

```{r network_stability_edges, echo=TRUE, warning=FALSE, message= FALSE}
set.seed(1331)
b1 <- bootnet(mynetwork.exp1,  nBoots= 10000, nCores = 1,
              statistics = c("strength","expectedInfluence","edge"),caseN = 50)

tb.b1 = summary(b1)

table_exp1_boot <- knitr::kable(tb.b1 , "html", caption = "Table Experiment 1") %>%
 kableExtra::kable_styling(latex_options = "HOLD_position", position = "center", full_width = F) %>%
  row_spec(0,bold=T,align='c')

table_exp1_boot

plot (b1, plot = "interval", split0 = TRUE, order="sample", labels=T)
```

And for centrality indices:

```{r network_stability, echo=TRUE, warning=FALSE, message=FALSE}
set.seed(1331)
b2 <- bootnet(mynetwork.exp1,nBoots= 10000, nCores = 1, type = "case",
              statistics = c("strength","expectedInfluence","edge"),caseN = 50)


corStability(b2)

plot (b2, c("expectedInfluence")) # Centrality stability graph
```
 
## Power analysis to determine the sample size for the next experiment

To determine the sample size of Experiment 2, we can use the sample from Experiment 1 and run a power analysis.

```{r poweranalysis, echo=TRUE, warning = FALSE, message=FALSE}
simRes <- netSimulator(mynetwork.exp1 ,
                        default = "EBICglasso",
                        nCases = c(150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400),
                        nReps = 100)
# simRes
plot(simRes)
plot(simRes, yvar = c("strength", "closeness", "betweenness"))
```

From the plot we can estimate that with 250 participants we would have enough power
to estimate the strength, betweenness and closeness of the network.
